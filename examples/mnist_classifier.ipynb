{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "mnist_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G_K_wH-NNZ0I",
        "_4fNS1a5N7dV"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.13 64-bit ('QC_RL': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "a02a61849171617a0da370a2b2ecb0f2b7aebd8796d470eac12a089e556a21e6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Mnist classification with orthogonal Neural Networks**"
      ],
      "metadata": {
        "id": "_ka823IqNNz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "G_K_wH-NNZ0I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!pip install dm-haiku optax\n",
        "!pip install git+https://github.com/qdevpsi3/quantum-orthogonal-nn.git"
      ],
      "outputs": [],
      "metadata": {
        "id": "qoPUTG3pguyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "zXofzwMRNc9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import array\n",
        "import gzip\n",
        "import os\n",
        "import struct\n",
        "import sys\n",
        "import urllib.request\n",
        "from os import path\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import orthax"
      ],
      "outputs": [],
      "metadata": {
        "id": "ggcO1-v9Nijz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "## uncomment to use Colab TPU\n",
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()"
      ],
      "outputs": [],
      "metadata": {
        "id": "VK5i_um1OAnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mnist Dataset\n",
        "\n",
        "adapted from : https://github.com/google/jax/blob/main/examples/datasets.py"
      ],
      "metadata": {
        "id": "lUkgM99mNqTo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "def mnist_raw():\n",
        "    base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
        "\n",
        "    _DATA = \"/tmp/\"\n",
        "\n",
        "    def _download(url, filename):\n",
        "        \"\"\"Download a url to a file in the JAX data temp directory.\"\"\"\n",
        "\n",
        "        if not path.exists(_DATA):\n",
        "            os.makedirs(_DATA)\n",
        "        out_file = path.join(_DATA, filename)\n",
        "        if not path.isfile(out_file):\n",
        "            urllib.request.urlretrieve(url, out_file)\n",
        "            print(\"downloaded {} to {}\".format(url, _DATA))\n",
        "\n",
        "    def parse_labels(filename):\n",
        "        with gzip.open(filename, \"rb\") as fh:\n",
        "            _ = struct.unpack(\">II\", fh.read(8))\n",
        "            return np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
        "\n",
        "    def parse_images(filename):\n",
        "        with gzip.open(filename, \"rb\") as fh:\n",
        "            _, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "            return np.array(array.array(\"B\", fh.read()),\n",
        "                            dtype=np.uint8).reshape(num_data, rows, cols)\n",
        "\n",
        "    for filename in [\n",
        "            \"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\",\n",
        "            \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"\n",
        "    ]:\n",
        "        _download(base_url + filename, filename)\n",
        "\n",
        "    train_images = parse_images(path.join(_DATA, \"train-images-idx3-ubyte.gz\"))\n",
        "    train_labels = parse_labels(path.join(_DATA, \"train-labels-idx1-ubyte.gz\"))\n",
        "    test_images = parse_images(path.join(_DATA, \"t10k-images-idx3-ubyte.gz\"))\n",
        "    test_labels = parse_labels(path.join(_DATA, \"t10k-labels-idx1-ubyte.gz\"))\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "def mnist(digits=None):\n",
        "    def _maybe_filter(images, labels, digits):\n",
        "        mask = np.isin(labels, digits)\n",
        "        return images[mask], labels[mask]\n",
        "\n",
        "    def _partial_flatten(x):\n",
        "        return np.reshape(x, (x.shape[0], -1))\n",
        "\n",
        "    def _one_hot(x, d, dtype=np.float32):\n",
        "        return np.array(x[:, None] == d, dtype)\n",
        "\n",
        "    train_images, train_labels, test_images, test_labels = mnist_raw()\n",
        "    if digits is not None:\n",
        "        train_images, train_labels = _maybe_filter(train_images, train_labels,\n",
        "                                                   digits)\n",
        "        test_images, test_labels = _maybe_filter(test_images, test_labels,\n",
        "                                                 digits)\n",
        "        train_labels = _one_hot(train_labels, np.array(digits))\n",
        "        test_labels = _one_hot(test_labels, np.array(digits))\n",
        "    else:\n",
        "        train_labels = _one_hot(train_labels, np.arange(10))\n",
        "        test_labels = _one_hot(test_labels, np.arange(10))\n",
        "\n",
        "    train_images = _partial_flatten(train_images) / np.float32(255.)\n",
        "    test_images = _partial_flatten(test_images) / np.float32(255.)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "def pca(train_x, test_x, n_components=8):\n",
        "    decomposition = PCA(n_components).fit(train_x)\n",
        "    train_x = decomposition.transform(train_x)\n",
        "    test_x = decomposition.transform(test_x)\n",
        "    return train_x, test_x"
      ],
      "outputs": [],
      "metadata": {
        "id": "hLtwRiRuNtDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "_4fNS1a5N7dV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# training parameters\n",
        "seed = 123\n",
        "batch_size = 50\n",
        "n_components = 8\n",
        "digits = [6,9]\n",
        "learning_rate = 0.001\n",
        "train_steps = 5000\n",
        "\n",
        "# network parameters\n",
        "output_sizes = [4,2]\n",
        "normalize_inputs = False\n",
        "with_bias = True\n",
        "t_init = hk.initializers.RandomUniform(minval=-np.pi, maxval=np.pi)\n",
        "b_init = hk.initializers.Constant(0.)\n",
        "activation = jax.nn.sigmoid\n",
        "activate_final = False"
      ],
      "outputs": [],
      "metadata": {
        "id": "e6fIpBGvN-Pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "adapted from : https://github.com/deepmind/dm-haiku/blob/main/examples/mnist.py"
      ],
      "metadata": {
        "id": "m37Ct9V5OMaN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "\n",
        "\n",
        "# set random state\n",
        "random_state = np.random.RandomState(seed)\n",
        "rng_key = jax.random.PRNGKey(\n",
        "    random_state.randint(-sys.maxsize - 1, sys.maxsize + 1,\n",
        "                            dtype=np.int64))\n",
        "\n",
        "# load data\n",
        "train_images, train_labels, test_images, test_labels = jax.device_put(mnist(digits))\n",
        "train_features, test_features = pca(train_images, test_images,\n",
        "                                    n_components)\n",
        "\n",
        "# build batch iterator\n",
        "num_train = train_images.shape[0]\n",
        "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "def data_stream(batch_size):\n",
        "    while True:\n",
        "        perm = random_state.permutation(num_train)\n",
        "        for i in range(num_batches):\n",
        "            batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "            yield train_features[batch_idx], train_labels[batch_idx]\n",
        "\n",
        "batches = iter(data_stream(batch_size))\n",
        "\n",
        "# build network\n",
        "def orthogonal_net(x):\n",
        "    module = orthax.haiku.OrthogonalMLP(output_sizes, \n",
        "                           normalize_inputs,\n",
        "                           with_bias,\n",
        "                           t_init,\n",
        "                           b_init,\n",
        "                           activation, \n",
        "                           activate_final)\n",
        "    return module(x)\n",
        "net = hk.without_apply_rng(hk.transform(orthogonal_net))\n",
        "params = avg_params = net.init(rng_key, next(batches)[0])\n",
        "\n",
        "# build optimizer\n",
        "opt = optax.rmsprop(learning_rate)\n",
        "opt_state = opt.init(params)\n",
        "\n",
        "# build model\n",
        "def loss(params, features, labels):\n",
        "    logits = net.apply(params, features)\n",
        "    l2_loss = 0.5 * sum(\n",
        "        jnp.sum(jnp.square(p)) for p in jax.tree_leaves(params))\n",
        "    softmax_xent = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
        "    softmax_xent /= labels.shape[0]\n",
        "    return softmax_xent + 1e-4 * l2_loss\n",
        "\n",
        "@jax.jit\n",
        "def accuracy(params, features, labels):\n",
        "    predictions = net.apply(params, features)\n",
        "    return jnp.mean(\n",
        "        jnp.argmax(predictions, axis=1) == jnp.argmax(labels, axis=1))\n",
        "\n",
        "@jax.jit\n",
        "def update(params, opt_state, features, labels):\n",
        "    grads = jax.grad(loss)(params, features, labels)\n",
        "    updates, opt_state = opt.update(grads, opt_state)\n",
        "    new_params = optax.apply_updates(params, updates)\n",
        "    return new_params, opt_state\n",
        "\n",
        "@jax.jit\n",
        "def ema_update(params, avg_params):\n",
        "    return optax.incremental_update(params, avg_params, step_size=0.001)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloaded https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz to /tmp/\n",
            "downloaded https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz to /tmp/\n",
            "downloaded https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz to /tmp/\n",
            "downloaded https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz to /tmp/\n"
          ]
        }
      ],
      "metadata": {
        "id": "7tOtLdACOLsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training/Evaluation loop\n",
        "\n",
        "adapted from : https://github.com/deepmind/dm-haiku/blob/main/examples/mnist.py"
      ],
      "metadata": {
        "id": "aGa5LotwOUve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# train/eval loop.\n",
        "for step in range(train_steps):\n",
        "    batch_features, batch_labels = next(batches)\n",
        "    if step % 100 == 0:\n",
        "        # evaluate classification accuracy on train & test sets.\n",
        "        train_accuracy = accuracy(avg_params, batch_features, batch_labels)\n",
        "        test_accuracy = accuracy(avg_params, test_features, test_labels)\n",
        "        train_accuracy, test_accuracy = jax.device_get(\n",
        "            (train_accuracy, test_accuracy))\n",
        "        print(f\"[Step {step}] Train / Test accuracy: \"\n",
        "                f\"{train_accuracy:.3f} / {test_accuracy:.3f}.\")\n",
        "\n",
        "    # update params\n",
        "    params, opt_state = update(params, opt_state, train_features,\n",
        "                                train_labels)\n",
        "    avg_params = ema_update(params, avg_params)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 0] Train / Test accuracy: 0.400 / 0.526.\n",
            "[Step 100] Train / Test accuracy: 0.480 / 0.533.\n",
            "[Step 200] Train / Test accuracy: 0.480 / 0.540.\n",
            "[Step 300] Train / Test accuracy: 0.580 / 0.564.\n",
            "[Step 400] Train / Test accuracy: 0.580 / 0.587.\n",
            "[Step 500] Train / Test accuracy: 0.660 / 0.617.\n",
            "[Step 600] Train / Test accuracy: 0.620 / 0.650.\n",
            "[Step 700] Train / Test accuracy: 0.540 / 0.690.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7fe2908d492b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# update params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     params, opt_state = update(params, opt_state, train_features,\n\u001b[0;32m---> 15\u001b[0;31m                                 train_labels)\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mavg_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mema_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/QC_RL/lib/python3.6/site-packages/haiku/_src/data_structures.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(treedef, leaves)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mFlatMapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_leaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     lambda treedef, leaves: FlatMapping(FlatComponents(leaves, treedef)))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;31m#      _                               _           _\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "id": "MbFCyNh2FB-0"
      }
    }
  ]
}