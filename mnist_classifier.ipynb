{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "mnist_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G_K_wH-NNZ0I",
        "_4fNS1a5N7dV"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Mnist classification with orthogonal Neural Networks**"
      ],
      "metadata": {
        "id": "_ka823IqNNz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "G_K_wH-NNZ0I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install dm-haiku optax"
      ],
      "outputs": [],
      "metadata": {
        "id": "qoPUTG3pguyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "zXofzwMRNc9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import array\n",
        "import gzip\n",
        "import os\n",
        "import struct\n",
        "import sys\n",
        "import urllib.request\n",
        "from os import path\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "from sklearn.decomposition import PCA"
      ],
      "outputs": [],
      "metadata": {
        "id": "ggcO1-v9Nijz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## uncomment to use Colab TPU\n",
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()"
      ],
      "outputs": [],
      "metadata": {
        "id": "VK5i_um1OAnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mnist Dataset\n",
        "\n",
        "adapted from : https://github.com/google/jax/blob/main/examples/datasets.py"
      ],
      "metadata": {
        "id": "lUkgM99mNqTo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def mnist_raw():\n",
        "    base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
        "\n",
        "    _DATA = \"/tmp/\"\n",
        "\n",
        "    def _download(url, filename):\n",
        "        \"\"\"Download a url to a file in the JAX data temp directory.\"\"\"\n",
        "\n",
        "        if not path.exists(_DATA):\n",
        "            os.makedirs(_DATA)\n",
        "        out_file = path.join(_DATA, filename)\n",
        "        if not path.isfile(out_file):\n",
        "            urllib.request.urlretrieve(url, out_file)\n",
        "            print(\"downloaded {} to {}\".format(url, _DATA))\n",
        "\n",
        "    def parse_labels(filename):\n",
        "        with gzip.open(filename, \"rb\") as fh:\n",
        "            _ = struct.unpack(\">II\", fh.read(8))\n",
        "            return np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
        "\n",
        "    def parse_images(filename):\n",
        "        with gzip.open(filename, \"rb\") as fh:\n",
        "            _, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "            return np.array(array.array(\"B\", fh.read()),\n",
        "                            dtype=np.uint8).reshape(num_data, rows, cols)\n",
        "\n",
        "    for filename in [\n",
        "            \"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\",\n",
        "            \"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\"\n",
        "    ]:\n",
        "        _download(base_url + filename, filename)\n",
        "\n",
        "    train_images = parse_images(path.join(_DATA, \"train-images-idx3-ubyte.gz\"))\n",
        "    train_labels = parse_labels(path.join(_DATA, \"train-labels-idx1-ubyte.gz\"))\n",
        "    test_images = parse_images(path.join(_DATA, \"t10k-images-idx3-ubyte.gz\"))\n",
        "    test_labels = parse_labels(path.join(_DATA, \"t10k-labels-idx1-ubyte.gz\"))\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "def mnist(digits=None):\n",
        "    def _maybe_filter(images, labels, digits):\n",
        "        mask = np.isin(labels, digits)\n",
        "        return images[mask], labels[mask]\n",
        "\n",
        "    def _partial_flatten(x):\n",
        "        return np.reshape(x, (x.shape[0], -1))\n",
        "\n",
        "    def _one_hot(x, d, dtype=np.float32):\n",
        "        return np.array(x[:, None] == d, dtype)\n",
        "\n",
        "    train_images, train_labels, test_images, test_labels = mnist_raw()\n",
        "    if digits is not None:\n",
        "        train_images, train_labels = _maybe_filter(train_images, train_labels,\n",
        "                                                   digits)\n",
        "        test_images, test_labels = _maybe_filter(test_images, test_labels,\n",
        "                                                 digits)\n",
        "        train_labels = _one_hot(train_labels, np.array(digits))\n",
        "        test_labels = _one_hot(test_labels, np.array(digits))\n",
        "    else:\n",
        "        train_labels = _one_hot(train_labels, np.arange(10))\n",
        "        test_labels = _one_hot(test_labels, np.arange(10))\n",
        "\n",
        "    train_images = _partial_flatten(train_images) / np.float32(255.)\n",
        "    test_images = _partial_flatten(test_images) / np.float32(255.)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "def pca(train_x, test_x, n_components=8):\n",
        "    decomposition = PCA(n_components).fit(train_x)\n",
        "    train_x = decomposition.transform(train_x)\n",
        "    test_x = decomposition.transform(test_x)\n",
        "    return train_x, test_x"
      ],
      "outputs": [],
      "metadata": {
        "id": "hLtwRiRuNtDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Orthogonal Neural Networks"
      ],
      "metadata": {
        "id": "IL4EAohKNx6S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def orthogonal_network_builder(output_sizes=[4, 2],\n",
        "                               with_bias=True,\n",
        "                               activation=jax.nn.sigmoid,\n",
        "                               activate_final=False,\n",
        "                               normalize=False):\n",
        "    def network_fn(x):\n",
        "\n",
        "        for idx, size in enumerate(output_sizes):\n",
        "\n",
        "            wires = jnp.array([\n",
        "                j for i in range(1, x.shape[-1])\n",
        "                for j in range(i, max(0, i - size), -1)\n",
        "            ])\n",
        "\n",
        "            thetas_init = hk.initializers.RandomUniform(minval=-np.pi,\n",
        "                                                        maxval=np.pi)\n",
        "            thetas = hk.get_parameter(\"thetas_{}\".format(idx),\n",
        "                                      shape=[len(wires)],\n",
        "                                      dtype=x.dtype,\n",
        "                                      init=thetas_init)\n",
        "\n",
        "            if normalize:\n",
        "                norm = jnp.linalg.norm(x, axis=1)[..., None]\n",
        "                x /= jax.lax.stop_gradient(norm)\n",
        "\n",
        "            def loop(i, x):\n",
        "                j, theta = wires[i], thetas[i]\n",
        "                cos_t, sin_t = jnp.cos(theta), jnp.sin(theta)\n",
        "                a_t, b_t = x[:, j - 1], x[:, j]\n",
        "                c_t, d_t = cos_t * a_t - sin_t * b_t, sin_t * a_t + cos_t * b_t\n",
        "                x = jax.ops.index_update(x, jax.ops.index[:, j - 1], c_t)\n",
        "                x = jax.ops.index_update(x, jax.ops.index[:, j], d_t)\n",
        "                return x\n",
        "\n",
        "            x = jax.lax.fori_loop(0, len(wires), loop, x)\n",
        "\n",
        "            if with_bias:\n",
        "                b_init = hk.initializers.Constant(0.)\n",
        "                b = hk.get_parameter(\"b_{}\".format(idx),\n",
        "                                     shape=[x.shape[-1]],\n",
        "                                     dtype=x.dtype,\n",
        "                                     init=b_init)\n",
        "                x += b\n",
        "\n",
        "            if (idx < len(output_sizes) - 1) or activate_final:\n",
        "                x = activation(x)\n",
        "\n",
        "            x = x[:, -size:]\n",
        "\n",
        "        return x\n",
        "\n",
        "    return network_fn"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ps3knJjnNxeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "_4fNS1a5N7dV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# set parameters\n",
        "seed = 123\n",
        "batch_size = 50\n",
        "n_components = 8\n",
        "digits = [6,9]\n",
        "output_sizes = [4,2]\n",
        "with_bias = False\n",
        "activation = jax.nn.selu\n",
        "activate_final = False\n",
        "normalize = False\n",
        "learning_rate = 0.001\n",
        "train_steps = 5000"
      ],
      "outputs": [],
      "metadata": {
        "id": "e6fIpBGvN-Pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "adapted from : https://github.com/deepmind/dm-haiku/blob/main/examples/mnist.py"
      ],
      "metadata": {
        "id": "m37Ct9V5OMaN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "\n",
        "# set random state\n",
        "random_state = np.random.RandomState(seed)\n",
        "rng_key = jax.random.PRNGKey(\n",
        "    random_state.randint(-sys.maxsize - 1, sys.maxsize + 1,\n",
        "                            dtype=np.int64))\n",
        "\n",
        "# load data\n",
        "train_images, train_labels, test_images, test_labels = jax.device_put(mnist(digits))\n",
        "train_features, test_features = pca(train_images, test_images,\n",
        "                                    n_components)\n",
        "\n",
        "# build batch iterator\n",
        "num_train = train_images.shape[0]\n",
        "num_complete_batches, leftover = divmod(num_train, batch_size)\n",
        "num_batches = num_complete_batches + bool(leftover)\n",
        "\n",
        "def data_stream(batch_size):\n",
        "    while True:\n",
        "        perm = random_state.permutation(num_train)\n",
        "        for i in range(num_batches):\n",
        "            batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "            yield train_features[batch_idx], train_labels[batch_idx]\n",
        "\n",
        "batches = iter(data_stream(batch_size))\n",
        "\n",
        "# build network\n",
        "net_fn = orthogonal_network_builder(output_sizes, with_bias, activation,\n",
        "                                    activate_final, normalize)\n",
        "net = hk.without_apply_rng(hk.transform(net_fn))\n",
        "params = avg_params = net.init(rng_key, next(batches)[0])\n",
        "\n",
        "# build optimizer\n",
        "opt = optax.rmsprop(learning_rate)\n",
        "opt_state = opt.init(params)\n",
        "\n",
        "# build model\n",
        "def loss(params, features, labels):\n",
        "    logits = net.apply(params, features)\n",
        "    l2_loss = 0.5 * sum(\n",
        "        jnp.sum(jnp.square(p)) for p in jax.tree_leaves(params))\n",
        "    softmax_xent = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
        "    softmax_xent /= labels.shape[0]\n",
        "    return softmax_xent + 1e-4 * l2_loss\n",
        "\n",
        "@jax.jit\n",
        "def accuracy(params, features, labels):\n",
        "    predictions = net.apply(params, features)\n",
        "    return jnp.mean(\n",
        "        jnp.argmax(predictions, axis=1) == jnp.argmax(labels, axis=1))\n",
        "\n",
        "@jax.jit\n",
        "def update(params, opt_state, features, labels):\n",
        "    grads = jax.grad(loss)(params, features, labels)\n",
        "    updates, opt_state = opt.update(grads, opt_state)\n",
        "    new_params = optax.apply_updates(params, updates)\n",
        "    return new_params, opt_state\n",
        "\n",
        "@jax.jit\n",
        "def ema_update(params, avg_params):\n",
        "    return optax.incremental_update(params, avg_params, step_size=0.001)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7tOtLdACOLsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training/Evaluation loop\n",
        "\n",
        "adapted from : https://github.com/deepmind/dm-haiku/blob/main/examples/mnist.py"
      ],
      "metadata": {
        "id": "aGa5LotwOUve"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# train/eval loop.\n",
        "for step in range(train_steps):\n",
        "    batch_features, batch_labels = next(batches)\n",
        "    if step % 100 == 0:\n",
        "        # evaluate classification accuracy on train & test sets.\n",
        "        train_accuracy = accuracy(avg_params, batch_features, batch_labels)\n",
        "        test_accuracy = accuracy(avg_params, test_features, test_labels)\n",
        "        train_accuracy, test_accuracy = jax.device_get(\n",
        "            (train_accuracy, test_accuracy))\n",
        "        print(f\"[Step {step}] Train / Test accuracy: \"\n",
        "                f\"{train_accuracy:.3f} / {test_accuracy:.3f}.\")\n",
        "\n",
        "    # update params\n",
        "    params, opt_state = update(params, opt_state, train_features,\n",
        "                                train_labels)\n",
        "    avg_params = ema_update(params, avg_params)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "MbFCyNh2FB-0"
      }
    }
  ]
}